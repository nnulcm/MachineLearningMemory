{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated CNN\n",
    "\n",
    "《Language Modeling with Gated Convolutional Networks》\n",
    "\n",
    "Yann N. Dauphin  \n",
    "Angela Fan  \n",
    "Michael Auli  \n",
    "David Grangier  \n",
    "Facebook AI Research\n",
    "\n",
    "### author qhduan@memect.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本量：12126，测试集样本量：3032\n"
     ]
    }
   ],
   "source": [
    "from data import X_train, X_test, y_train, y_test\n",
    "from data import fit_vectorizer, fit_onehot\n",
    "from data import batch_flow, test_batch_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个训练样本最大长度：14\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "PAD = ' ' # 句子不到max_len长度时的占位符\n",
    "max_len = max(len(x) for x in X_train)\n",
    "print('单个训练样本最大长度：{}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = fit_vectorizer(X_train, embedding_size, max_len, PAD)\n",
    "onehot = fit_onehot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps 14\n",
      "input_size 128\n",
      "target_size 2\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_epoch = 20\n",
    "hidden_size = 512\n",
    "batch_size = 256\n",
    "time_steps = max_len\n",
    "input_size = embedding_size\n",
    "target_size = len(onehot.feature_indices_)\n",
    "print('time_steps', time_steps)\n",
    "print('input_size', input_size)\n",
    "print('target_size', target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 14, 128) (256, 2)\n"
     ]
    }
   ],
   "source": [
    "test_batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [batch_size, time_steps, input_size, 1], name='X')\n",
    "y = tf.placeholder(tf.float32, [batch_size, target_size], name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pitch_1 = tf.Variable(tf.random_normal([5, 19, 1, 32]), name='pitch_1')\n",
    "pitch_1_bias = tf.Variable(tf.random_normal([32]), name='pitch_1_bias')\n",
    "\n",
    "pitch_2 = tf.Variable(tf.random_normal([5, 19, 1, 32]), name='pitch_2')\n",
    "pitch_2_bias = tf.Variable(tf.random_normal([32]), name='pitch_2_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_1 = tf.nn.bias_add(\n",
    "    tf.nn.conv2d(\n",
    "        X, pitch_1, strides=[1, 1, 1, 1], padding='VALID'\n",
    "    ),\n",
    "    pitch_1_bias,\n",
    "    name='bias_add_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_2 = tf.nn.bias_add(\n",
    "    tf.nn.conv2d(\n",
    "        X, pitch_2, strides=[1, 1, 1, 1], padding='VALID'\n",
    "    ),\n",
    "    pitch_2_bias,\n",
    "    name='bias_add_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_2 = tf.sigmoid(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 110, 32)\n"
     ]
    }
   ],
   "source": [
    "print(conv_1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 110, 32)\n"
     ]
    }
   ],
   "source": [
    "print(conv_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 110, 32)\n"
     ]
    }
   ],
   "source": [
    "flatten = conv_1 * conv_2\n",
    "print(flatten.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatten = tf.reshape(flatten, [batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 35200)\n"
     ]
    }
   ],
   "source": [
    "print(flatten.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_1 = tf.Variable(tf.random_normal([int(flatten.get_shape()[1]), target_size]), name='weight_1')\n",
    "bias_1 = tf.Variable(tf.random_normal([target_size]), name='bias_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_connect = tf.add(\n",
    "    tf.matmul(flatten, weight_1, name='matmul_2'),\n",
    "    bias_1,\n",
    "    name='add_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(256), Dimension(2)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_connect.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = full_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        pred, y\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初始化所有变量\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 本来是要关，不过CNN不用GPU真的好慢……\n",
    "# disable GPU，关闭GPU支持\n",
    "config = tf.ConfigProto(\n",
    "#     device_count = {'GPU': 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cost: 47.4133 acc: 0.5625\n",
      "epoch 1 cost: 40.7791 acc: 0.5859\n",
      "epoch 2 cost: 35.5414 acc: 0.5859\n",
      "epoch 3 cost: 31.1322 acc: 0.6094\n",
      "epoch 4 cost: 27.4881 acc: 0.6328\n",
      "epoch 5 cost: 24.4705 acc: 0.6523\n",
      "epoch 6 cost: 21.9796 acc: 0.6641\n",
      "epoch 7 cost: 19.9095 acc: 0.6680\n",
      "epoch 8 cost: 18.1795 acc: 0.6641\n",
      "epoch 9 cost: 16.6883 acc: 0.6680\n",
      "epoch 10 cost: 15.4159 acc: 0.6836\n",
      "epoch 11 cost: 14.2943 acc: 0.6992\n",
      "epoch 12 cost: 13.3381 acc: 0.7188\n",
      "epoch 13 cost: 12.4947 acc: 0.7148\n",
      "epoch 14 cost: 11.7470 acc: 0.7109\n",
      "epoch 15 cost: 11.1106 acc: 0.7500\n",
      "epoch 16 cost: 10.5260 acc: 0.7695\n",
      "epoch 17 cost: 9.9895 acc: 0.7305\n",
      "epoch 18 cost: 9.5880 acc: 0.7344\n",
      "epoch 19 cost: 9.2583 acc: 0.7812\n",
      "epoch 20 cost: 8.8758 acc: 0.7305\n",
      "train cost: 8.6559 acc: 0.7305\n",
      "test cost: 15.0292 acc: 0.6328\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch + 1):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "            feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "            sess.run(train_step, feeds)\n",
    "            c, acc = sess.run([cost, accuracy], feeds)\n",
    "            costs.append(c)\n",
    "            accs.append(acc)\n",
    "        print('epoch {} cost: {:.4f} acc: {:.4f}'.format(\n",
    "            epoch, np.mean(costs), np.mean(acc)\n",
    "        ))\n",
    "    # train\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('train cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))\n",
    "    # test\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_test, y_test, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('test cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "要么过拟合，要么拟合不了，文本pitch的参数没什么经验～～不知道是不是程序写的有问题……应该不是吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
