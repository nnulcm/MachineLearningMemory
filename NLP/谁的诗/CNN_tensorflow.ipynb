{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "### author qhduan@memect.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本量：12126，测试集样本量：3032\n"
     ]
    }
   ],
   "source": [
    "from data import X_train, X_test, y_train, y_test\n",
    "from data import fit_vectorizer, fit_onehot\n",
    "from data import batch_flow, test_batch_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个训练样本最大长度：14\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "PAD = ' ' # 句子不到max_len长度时的占位符\n",
    "max_len = max(len(x) for x in X_train)\n",
    "print('单个训练样本最大长度：{}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = fit_vectorizer(X_train, embedding_size, max_len, PAD)\n",
    "onehot = fit_onehot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps 14\n",
      "input_size 128\n",
      "target_size 2\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_epoch = 20\n",
    "hidden_size = 512\n",
    "batch_size = 256\n",
    "time_steps = max_len\n",
    "input_size = embedding_size\n",
    "target_size = len(onehot.feature_indices_)\n",
    "print('time_steps', time_steps)\n",
    "print('input_size', input_size)\n",
    "print('target_size', target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 14, 128) (256, 2)\n"
     ]
    }
   ],
   "source": [
    "test_batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [batch_size, time_steps, input_size, 1], name='X')\n",
    "y = tf.placeholder(tf.float32, [batch_size, target_size], name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pitch_1 = tf.Variable(tf.random_normal([5, 11, 1, 32]), name='pitch_1')\n",
    "pitch_1_bias = tf.Variable(tf.random_normal([32]), name='pitch_1_bias')\n",
    "\n",
    "pitch_2 = tf.Variable(tf.random_normal([3, 7, 32, 64]), name='pitch_2')\n",
    "pitch_2_bias = tf.Variable(tf.random_normal([64]), name='pitch_2_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_1 = tf.nn.relu(\n",
    "    tf.nn.bias_add(\n",
    "        tf.nn.conv2d(\n",
    "            X, pitch_1, strides=[1, 1, 1, 1], padding='VALID'\n",
    "        ),\n",
    "        pitch_1_bias,\n",
    "        name='bias_add_1'\n",
    "    ),\n",
    "    name='relu_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 118, 32)\n"
     ]
    }
   ],
   "source": [
    "print(conv_1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxpool_1 = tf.nn.max_pool(\n",
    "    conv_1,\n",
    "    ksize=[1, 1, 8, 1],\n",
    "    strides=[1, 1, 4, 1],\n",
    "    padding='SAME',\n",
    "    name='max_pool_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 30, 32)\n"
     ]
    }
   ],
   "source": [
    "print(maxpool_1.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_2 = tf.nn.relu(\n",
    "    tf.nn.bias_add(\n",
    "        tf.nn.conv2d(\n",
    "            maxpool_1, pitch_2, strides=[1, 1, 1, 1], padding='VALID'\n",
    "        ),\n",
    "        pitch_2_bias,\n",
    "        name='bias_add_2'\n",
    "    ),\n",
    "    name='relu_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8, 24, 64)\n"
     ]
    }
   ],
   "source": [
    "print(conv_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxpool_2 = tf.nn.max_pool(\n",
    "    conv_2,\n",
    "    ksize=[1, 1, 4, 1],\n",
    "    strides=[1, 1, 2, 1],\n",
    "    padding='SAME',\n",
    "    name='max_pool_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8, 12, 64)\n"
     ]
    }
   ],
   "source": [
    "print(maxpool_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatten = tf.reshape(maxpool_2, [batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 6144)\n"
     ]
    }
   ],
   "source": [
    "print(flatten.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_1 = tf.Variable(tf.random_normal([int(flatten.get_shape()[1]), hidden_size]), name='weight_1')\n",
    "bias_1 = tf.Variable(tf.random_normal([hidden_size]), name='bias_1')\n",
    "\n",
    "weight_2 = tf.Variable(tf.random_normal([hidden_size, target_size]), name='weight_2')\n",
    "bias_2 = tf.Variable(tf.random_normal([target_size]), name='bias_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_connect_1 = tf.nn.relu(\n",
    "    tf.add(\n",
    "        tf.matmul(flatten, weight_1, name='matmul_1'),\n",
    "        bias_1,\n",
    "        name='add_1'\n",
    "    ),\n",
    "    name='relu_3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_connect_2 = tf.add(\n",
    "    tf.matmul(full_connect_1, weight_2, name='matmul_2'),\n",
    "    bias_2,\n",
    "    name='add_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = full_connect_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        pred, y\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初始化所有变量\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 本来是要关，不过CNN不用GPU真的好慢……\n",
    "# disable GPU，关闭GPU支持\n",
    "config = tf.ConfigProto(\n",
    "#     device_count = {'GPU': 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cost: 7313.8301 acc: 0.5742\n",
      "epoch 1 cost: 4461.7412 acc: 0.5117\n",
      "epoch 2 cost: 3760.0442 acc: 0.4805\n",
      "epoch 3 cost: 3294.9746 acc: 0.5391\n",
      "epoch 4 cost: 2994.0645 acc: 0.5508\n",
      "epoch 5 cost: 2743.8994 acc: 0.5820\n",
      "epoch 6 cost: 2545.1111 acc: 0.6016\n",
      "epoch 7 cost: 2395.9573 acc: 0.6016\n",
      "epoch 8 cost: 2322.5354 acc: 0.6523\n",
      "epoch 9 cost: 2175.3826 acc: 0.6016\n",
      "epoch 10 cost: 2154.6729 acc: 0.5117\n",
      "epoch 11 cost: 2459.0969 acc: 0.6445\n",
      "epoch 12 cost: 2042.2045 acc: 0.6562\n",
      "epoch 13 cost: 1852.2140 acc: 0.6484\n",
      "epoch 14 cost: 1938.1312 acc: 0.7109\n",
      "epoch 15 cost: 1768.5895 acc: 0.7031\n",
      "epoch 16 cost: 1531.2202 acc: 0.7070\n",
      "epoch 17 cost: 1398.1149 acc: 0.6992\n",
      "epoch 18 cost: 1335.4600 acc: 0.7148\n",
      "epoch 19 cost: 1272.4141 acc: 0.7227\n",
      "epoch 20 cost: 1255.8632 acc: 0.6953\n",
      "train cost: 2050.3035 acc: 0.6953\n",
      "test cost: 3083.1321 acc: 0.6172\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch + 1):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "            feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "            sess.run(train_step, feeds)\n",
    "            c, acc = sess.run([cost, accuracy], feeds)\n",
    "            costs.append(c)\n",
    "            accs.append(acc)\n",
    "        print('epoch {} cost: {:.4f} acc: {:.4f}'.format(\n",
    "            epoch, np.mean(costs), np.mean(acc)\n",
    "        ))\n",
    "    # train\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_train, y_train, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('train cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))\n",
    "    # test\n",
    "    costs = []\n",
    "    accs = []\n",
    "    for X_sample, y_sample in batch_flow(X_test, y_test, batch_size, vectorizer, onehot, max_len, PAD):\n",
    "        feeds = {X: X_sample.reshape([batch_size, time_steps, input_size, 1]), y: y_sample}\n",
    "        c, acc = sess.run([cost, accuracy], feeds)\n",
    "        costs.append(c)\n",
    "        accs.append(acc)\n",
    "    print('test cost: {:.4f} acc: {:.4f}'.format(np.mean(costs), np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "要么过拟合，要么拟合不了，文本pitch的参数没什么经验～～不知道是不是程序写的有问题……应该不是吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
