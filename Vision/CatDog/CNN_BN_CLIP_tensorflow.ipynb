{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.481949803 65.2925375088\n"
     ]
    }
   ],
   "source": [
    "mean_of_train = np.mean(X_train)\n",
    "std_of_train = np.std(X_train)\n",
    "print(mean_of_train, std_of_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - mean_of_train) / std_of_train\n",
    "X_test = (X_test - mean_of_train) / std_of_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练数据数量：20000\n",
      "高度:128\n",
      "宽度：128\n",
      "通道数：3\n",
      "测试数据数量：5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_len, width, height, channel = X_train.shape\n",
    "test_len = X_test.shape[0]\n",
    "print(\"\"\"\n",
    "训练数据数量：{}\n",
    "高度:{}\n",
    "宽度：{}\n",
    "通道数：{}\n",
    "测试数据数量：{}\n",
    "\"\"\".format(train_len, width, height, channel, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tfkit' from '../../tfkit/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入我的自定义库 @qhduan\n",
    "import sys\n",
    "import importlib\n",
    "sys.path.insert(0, '../../')\n",
    "import tfkit\n",
    "importlib.reload(tfkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_size is 2\n"
     ]
    }
   ],
   "source": [
    "# 学习率\n",
    "learning_rate = 0.01\n",
    "# 迭代次数（批次）\n",
    "n_epoch = 50\n",
    "# 批次大小\n",
    "# 可能需要调小\n",
    "batch_size = 32\n",
    "# dropout\n",
    "dropout = 0.8\n",
    "# 输出大小\n",
    "target_size = y_train.shape[1]\n",
    "print('target_size is', target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 输入占位符\n",
    "X = tf.placeholder(tf.float32, [batch_size, width, height, channel])\n",
    "# 输出占位符\n",
    "y = tf.placeholder(tf.float32, [batch_size, target_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> (32, 62, 62, 64) \t conv_1\n",
      "===> (32, 31, 31, 64) \t mp_1\n",
      "===> (32, 14, 14, 128) \t conv_2\n",
      "===> (32, 7, 7, 128) \t mp_2\n",
      "===> (32, 5, 5, 256) \t conv_3\n",
      "===> (32, 2, 2, 256) \t mp_3\n",
      "===> (32, 1024) \t flatten\n",
      "===> (32, 512) \t fc_bn\n",
      "===> (32, 2) \t fc\n"
     ]
    }
   ],
   "source": [
    "model = X\n",
    "model = tfkit.conv(model, 64, (5, 5), 'conv_1', strides=(1, 2, 2, 1), activation='relu', batch_normalization=True)\n",
    "model = tfkit.max_pool(model, 'mp_1')\n",
    "model = tfkit.dropout(model, dropout)\n",
    "model = tfkit.conv(model, 128, (5, 5), 'conv_2', strides=(1, 2, 2, 1), activation='relu', batch_normalization=True)\n",
    "model = tfkit.max_pool(model, 'mp_2')\n",
    "model = tfkit.dropout(model, dropout)\n",
    "model = tfkit.conv(model, 256, (3, 3), 'conv_3', strides=(1, 1, 1, 1), activation='relu', batch_normalization=True)\n",
    "model = tfkit.max_pool(model, 'mp_3')\n",
    "model = tfkit.dropout(model, dropout)\n",
    "model = tfkit.flatten(model, 'flatten')\n",
    "model = tfkit.full_connect(model, 512, name='fc_bn', activation='relu', batch_normalization=True)\n",
    "model = tfkit.dropout(model, dropout)\n",
    "model = tfkit.full_connect(model, target_size, 'fc', activation='linear', batch_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step, cost = tfkit.train_softmax(\n",
    "    model, y,\n",
    "    opt=tf.train.AdadeltaOptimizer(learning_rate=learning_rate),\n",
    "    clip=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = [\n",
    "    cost,\n",
    "    tfkit.accuracy(model, y, softmax=True),\n",
    "    tfkit.precision(model, y, softmax=True),\n",
    "    tfkit.recall(model, y, softmax=True),\n",
    "    tfkit.f1(model, y, softmax=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "100%|██████████| 625/625 [00:22<00:00, 28.34it/s]\n",
      "train: loss: 0.6757, acc: 0.5974, prec: 0.6008, rec: 0.5874, f1: 0.5877\n",
      "test: loss: 0.6553, acc: 0.6152, prec: 0.6190, rec: 0.6106, f1: 0.6078\n",
      "epoch: 1\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.94it/s]\n",
      "train: loss: 0.6436, acc: 0.6301, prec: 0.6330, rec: 0.6295, f1: 0.6247\n",
      "test: loss: 0.6457, acc: 0.6276, prec: 0.6308, rec: 0.6305, f1: 0.6229\n",
      "epoch: 2\n",
      "100%|██████████| 625/625 [00:22<00:00, 28.00it/s]\n",
      "train: loss: 0.6324, acc: 0.6429, prec: 0.6443, rec: 0.6445, f1: 0.6379\n",
      "test: loss: 0.6288, acc: 0.6473, prec: 0.6514, rec: 0.6452, f1: 0.6409\n",
      "epoch: 3\n",
      "100%|██████████| 625/625 [00:22<00:00, 28.01it/s]\n",
      "train: loss: 0.6227, acc: 0.6496, prec: 0.6538, rec: 0.6494, f1: 0.6445\n",
      "test: loss: 0.6268, acc: 0.6521, prec: 0.6557, rec: 0.6537, f1: 0.6471\n",
      "epoch: 4\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.83it/s]\n",
      "train: loss: 0.6112, acc: 0.6655, prec: 0.6694, rec: 0.6662, f1: 0.6608\n",
      "test: loss: 0.6178, acc: 0.6576, prec: 0.6637, rec: 0.6529, f1: 0.6506\n",
      "epoch: 5\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.80it/s]\n",
      "train: loss: 0.6087, acc: 0.6636, prec: 0.6692, rec: 0.6567, f1: 0.6560\n",
      "test: loss: 0.6083, acc: 0.6680, prec: 0.6737, rec: 0.6650, f1: 0.6622\n",
      "epoch: 6\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.77it/s]\n",
      "train: loss: 0.5965, acc: 0.6774, prec: 0.6846, rec: 0.6680, f1: 0.6692\n",
      "test: loss: 0.6055, acc: 0.6694, prec: 0.6777, rec: 0.6602, f1: 0.6608\n",
      "epoch: 7\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.74it/s]\n",
      "train: loss: 0.5891, acc: 0.6835, prec: 0.6912, rec: 0.6739, f1: 0.6751\n",
      "test: loss: 0.5917, acc: 0.6843, prec: 0.6937, rec: 0.6688, f1: 0.6742\n",
      "epoch: 8\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.82it/s]\n",
      "train: loss: 0.5792, acc: 0.6950, prec: 0.7005, rec: 0.6921, f1: 0.6889\n",
      "test: loss: 0.5800, acc: 0.7008, prec: 0.7069, rec: 0.6964, f1: 0.6946\n",
      "epoch: 9\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.84it/s]\n",
      "train: loss: 0.5733, acc: 0.6993, prec: 0.7071, rec: 0.6909, f1: 0.6917\n",
      "test: loss: 0.5798, acc: 0.6939, prec: 0.6996, rec: 0.6868, f1: 0.6865\n",
      "epoch: 10\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.79it/s]\n",
      "train: loss: 0.5683, acc: 0.7009, prec: 0.7088, rec: 0.6927, f1: 0.6933\n",
      "test: loss: 0.5823, acc: 0.6947, prec: 0.7024, rec: 0.6846, f1: 0.6861\n",
      "epoch: 11\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.77it/s]\n",
      "train: loss: 0.5609, acc: 0.7080, prec: 0.7180, rec: 0.6970, f1: 0.7004\n",
      "test: loss: 0.5748, acc: 0.7048, prec: 0.7142, rec: 0.6912, f1: 0.6950\n",
      "epoch: 12\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.81it/s]\n",
      "train: loss: 0.5500, acc: 0.7194, prec: 0.7306, rec: 0.7057, f1: 0.7107\n",
      "test: loss: 0.5722, acc: 0.6984, prec: 0.7061, rec: 0.6879, f1: 0.6902\n",
      "epoch: 13\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.82it/s]\n",
      "train: loss: 0.5474, acc: 0.7195, prec: 0.7294, rec: 0.7091, f1: 0.7119\n",
      "test: loss: 0.5715, acc: 0.7028, prec: 0.7096, rec: 0.7033, f1: 0.6982\n",
      "epoch: 14\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.85it/s]\n",
      "train: loss: 0.5389, acc: 0.7289, prec: 0.7374, rec: 0.7211, f1: 0.7217\n",
      "test: loss: 0.5562, acc: 0.7156, prec: 0.7269, rec: 0.7013, f1: 0.7062\n",
      "epoch: 15\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.83it/s]\n",
      "train: loss: 0.5377, acc: 0.7270, prec: 0.7357, rec: 0.7201, f1: 0.7207\n",
      "test: loss: 0.5547, acc: 0.7152, prec: 0.7238, rec: 0.7069, f1: 0.7071\n",
      "epoch: 16\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.82it/s]\n",
      "train: loss: 0.5308, acc: 0.7326, prec: 0.7422, rec: 0.7251, f1: 0.7260\n",
      "test: loss: 0.5548, acc: 0.7191, prec: 0.7300, rec: 0.7031, f1: 0.7096\n",
      "epoch: 17\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.86it/s]\n",
      "train: loss: 0.5279, acc: 0.7371, prec: 0.7449, rec: 0.7322, f1: 0.7312\n",
      "test: loss: 0.5533, acc: 0.7144, prec: 0.7211, rec: 0.7121, f1: 0.7080\n",
      "epoch: 18\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.88it/s]\n",
      "train: loss: 0.5220, acc: 0.7432, prec: 0.7509, rec: 0.7383, f1: 0.7373\n",
      "test: loss: 0.5480, acc: 0.7261, prec: 0.7329, rec: 0.7166, f1: 0.7178\n",
      "epoch: 19\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.87it/s]\n",
      "train: loss: 0.5143, acc: 0.7462, prec: 0.7545, rec: 0.7412, f1: 0.7404\n",
      "test: loss: 0.5424, acc: 0.7289, prec: 0.7371, rec: 0.7212, f1: 0.7224\n",
      "epoch: 20\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.89it/s]\n",
      "train: loss: 0.5145, acc: 0.7488, prec: 0.7571, rec: 0.7429, f1: 0.7427\n",
      "test: loss: 0.5436, acc: 0.7325, prec: 0.7418, rec: 0.7218, f1: 0.7238\n",
      "epoch: 21\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.87it/s]\n",
      "train: loss: 0.5067, acc: 0.7550, prec: 0.7633, rec: 0.7509, f1: 0.7495\n",
      "test: loss: 0.5362, acc: 0.7297, prec: 0.7378, rec: 0.7231, f1: 0.7226\n",
      "epoch: 22\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.86it/s]\n",
      "train: loss: 0.5068, acc: 0.7538, prec: 0.7609, rec: 0.7506, f1: 0.7486\n",
      "test: loss: 0.5349, acc: 0.7313, prec: 0.7405, rec: 0.7264, f1: 0.7255\n",
      "epoch: 23\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.86it/s]\n",
      "train: loss: 0.4981, acc: 0.7561, prec: 0.7648, rec: 0.7498, f1: 0.7502\n",
      "test: loss: 0.5346, acc: 0.7319, prec: 0.7410, rec: 0.7240, f1: 0.7246\n",
      "epoch: 24\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.89it/s]\n",
      "train: loss: 0.4982, acc: 0.7601, prec: 0.7684, rec: 0.7540, f1: 0.7543\n",
      "test: loss: 0.5257, acc: 0.7402, prec: 0.7485, rec: 0.7387, f1: 0.7357\n",
      "epoch: 25\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.63it/s]\n",
      "train: loss: 0.4961, acc: 0.7621, prec: 0.7697, rec: 0.7587, f1: 0.7571\n",
      "test: loss: 0.5296, acc: 0.7367, prec: 0.7443, rec: 0.7349, f1: 0.7316\n",
      "epoch: 26\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.82it/s]\n",
      "train: loss: 0.4973, acc: 0.7584, prec: 0.7646, rec: 0.7568, f1: 0.7536\n",
      "test: loss: 0.5332, acc: 0.7353, prec: 0.7402, rec: 0.7325, f1: 0.7289\n",
      "epoch: 27\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.83it/s]\n",
      "train: loss: 0.4898, acc: 0.7621, prec: 0.7691, rec: 0.7600, f1: 0.7572\n",
      "test: loss: 0.5163, acc: 0.7418, prec: 0.7474, rec: 0.7441, f1: 0.7380\n",
      "epoch: 28\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.63it/s]\n",
      "train: loss: 0.4864, acc: 0.7694, prec: 0.7747, rec: 0.7698, f1: 0.7653\n",
      "test: loss: 0.5151, acc: 0.7444, prec: 0.7558, rec: 0.7362, f1: 0.7376\n",
      "epoch: 29\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.67it/s]\n",
      "train: loss: 0.4835, acc: 0.7667, prec: 0.7752, rec: 0.7614, f1: 0.7608\n",
      "test: loss: 0.5264, acc: 0.7436, prec: 0.7508, rec: 0.7391, f1: 0.7380\n",
      "epoch: 30\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.64it/s]\n",
      "train: loss: 0.4813, acc: 0.7692, prec: 0.7760, rec: 0.7681, f1: 0.7646\n",
      "test: loss: 0.5197, acc: 0.7406, prec: 0.7476, rec: 0.7371, f1: 0.7352\n",
      "epoch: 31\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.62it/s]\n",
      "train: loss: 0.4783, acc: 0.7704, prec: 0.7769, rec: 0.7672, f1: 0.7652\n",
      "test: loss: 0.5103, acc: 0.7524, prec: 0.7595, rec: 0.7498, f1: 0.7472\n",
      "epoch: 32\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.62it/s]\n",
      "train: loss: 0.4736, acc: 0.7768, prec: 0.7820, rec: 0.7790, f1: 0.7730\n",
      "test: loss: 0.5104, acc: 0.7530, prec: 0.7582, rec: 0.7535, f1: 0.7478\n",
      "epoch: 33\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.65it/s]\n",
      "train: loss: 0.4738, acc: 0.7770, prec: 0.7831, rec: 0.7747, f1: 0.7723\n",
      "test: loss: 0.5159, acc: 0.7526, prec: 0.7540, rec: 0.7599, f1: 0.7494\n",
      "epoch: 34\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.68it/s]\n",
      "train: loss: 0.4735, acc: 0.7746, prec: 0.7798, rec: 0.7746, f1: 0.7701\n",
      "test: loss: 0.5153, acc: 0.7514, prec: 0.7575, rec: 0.7516, f1: 0.7468\n",
      "epoch: 35\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.69it/s]\n",
      "train: loss: 0.4683, acc: 0.7803, prec: 0.7843, rec: 0.7817, f1: 0.7761\n",
      "test: loss: 0.5061, acc: 0.7488, prec: 0.7528, rec: 0.7533, f1: 0.7450\n",
      "epoch: 36\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.67it/s]\n",
      "train: loss: 0.4647, acc: 0.7837, prec: 0.7891, rec: 0.7841, f1: 0.7797\n",
      "test: loss: 0.5075, acc: 0.7560, prec: 0.7612, rec: 0.7542, f1: 0.7502\n",
      "epoch: 37\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.66it/s]\n",
      "train: loss: 0.4624, acc: 0.7818, prec: 0.7879, rec: 0.7825, f1: 0.7777\n",
      "test: loss: 0.5027, acc: 0.7584, prec: 0.7604, rec: 0.7642, f1: 0.7550\n",
      "epoch: 38\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.63it/s]\n",
      "train: loss: 0.4624, acc: 0.7863, prec: 0.7892, rec: 0.7916, f1: 0.7832\n",
      "test: loss: 0.4991, acc: 0.7558, prec: 0.7606, rec: 0.7586, f1: 0.7524\n",
      "epoch: 39\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.67it/s]\n",
      "train: loss: 0.4615, acc: 0.7812, prec: 0.7862, rec: 0.7820, f1: 0.7773\n",
      "test: loss: 0.5022, acc: 0.7586, prec: 0.7641, rec: 0.7578, f1: 0.7537\n",
      "epoch: 40\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.62it/s]\n",
      "train: loss: 0.4524, acc: 0.7873, prec: 0.7918, rec: 0.7896, f1: 0.7842\n",
      "test: loss: 0.5027, acc: 0.7530, prec: 0.7576, rec: 0.7564, f1: 0.7493\n",
      "epoch: 41\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.64it/s]\n",
      "train: loss: 0.4554, acc: 0.7851, prec: 0.7925, rec: 0.7830, f1: 0.7806\n",
      "test: loss: 0.4973, acc: 0.7584, prec: 0.7617, rec: 0.7637, f1: 0.7554\n",
      "epoch: 42\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.62it/s]\n",
      "train: loss: 0.4527, acc: 0.7873, prec: 0.7922, rec: 0.7877, f1: 0.7833\n",
      "test: loss: 0.4971, acc: 0.7629, prec: 0.7713, rec: 0.7610, f1: 0.7584\n",
      "epoch: 43\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.65it/s]\n",
      "train: loss: 0.4491, acc: 0.7925, prec: 0.7974, rec: 0.7933, f1: 0.7886\n",
      "test: loss: 0.4935, acc: 0.7590, prec: 0.7630, rec: 0.7612, f1: 0.7547\n",
      "epoch: 44\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.65it/s]\n",
      "train: loss: 0.4464, acc: 0.7909, prec: 0.7971, rec: 0.7911, f1: 0.7871\n",
      "test: loss: 0.4948, acc: 0.7673, prec: 0.7766, rec: 0.7633, f1: 0.7626\n",
      "epoch: 45\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.64it/s]\n",
      "train: loss: 0.4432, acc: 0.7955, prec: 0.8021, rec: 0.7951, f1: 0.7915\n",
      "test: loss: 0.4934, acc: 0.7655, prec: 0.7663, rec: 0.7734, f1: 0.7631\n",
      "epoch: 46\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.51it/s]\n",
      "train: loss: 0.4449, acc: 0.7942, prec: 0.8012, rec: 0.7942, f1: 0.7905\n",
      "test: loss: 0.4966, acc: 0.7548, prec: 0.7572, rec: 0.7638, f1: 0.7525\n",
      "epoch: 47\n",
      "100%|██████████| 625/625 [00:22<00:00, 27.20it/s]\n",
      "train: loss: 0.4407, acc: 0.7978, prec: 0.8037, rec: 0.7972, f1: 0.7939\n",
      "test: loss: 0.4890, acc: 0.7653, prec: 0.7713, rec: 0.7667, f1: 0.7616\n",
      "epoch: 48\n",
      "100%|██████████| 625/625 [00:23<00:00, 27.08it/s]\n",
      "train: loss: 0.4409, acc: 0.7961, prec: 0.8010, rec: 0.7982, f1: 0.7925\n",
      "test: loss: 0.4841, acc: 0.7693, prec: 0.7753, rec: 0.7736, f1: 0.7665\n",
      "epoch: 49\n",
      "100%|██████████| 625/625 [00:23<00:00, 26.59it/s]\n",
      "train: loss: 0.4416, acc: 0.7940, prec: 0.8008, rec: 0.7926, f1: 0.7899\n",
      "test: loss: 0.4928, acc: 0.7574, prec: 0.7591, rec: 0.7645, f1: 0.7537\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    total = int((len(X_train) - 1) / batch_size + 1)\n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch: {}'.format(epoch))\n",
    "        record = []\n",
    "        for batch_x, batch_y in tqdm(tfkit.batch_flow(X_train, y_train, batch_size), total=total, file=sys.stdout):\n",
    "            sess.run([train_step], feed_dict={X: batch_x, y: batch_y})\n",
    "            record.append(sess.run(measures, feed_dict={X: batch_x, y: batch_y}))\n",
    "        print('train: loss: {:.4f}, acc: {:.4f}, prec: {:.4f}, rec: {:.4f}, f1: {:.4f}'.format(\n",
    "            np.mean([x[0] for x in record]),\n",
    "            np.mean([x[1] for x in record]),\n",
    "            np.mean([x[2] for x in record]),\n",
    "            np.mean([x[3] for x in record]),\n",
    "            np.mean([x[4] for x in record])\n",
    "        ))\n",
    "        record = []\n",
    "        for batch_x, batch_y in tfkit.batch_flow(X_test, y_test, batch_size):\n",
    "            record.append(sess.run(measures, feed_dict={X: batch_x, y: batch_y}))\n",
    "        print('test: loss: {:.4f}, acc: {:.4f}, prec: {:.4f}, rec: {:.4f}, f1: {:.4f}'.format(\n",
    "            np.mean([x[0] for x in record]),\n",
    "            np.mean([x[1] for x in record]),\n",
    "            np.mean([x[2] for x in record]),\n",
    "            np.mean([x[3] for x in record]),\n",
    "            np.mean([x[4] for x in record])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
